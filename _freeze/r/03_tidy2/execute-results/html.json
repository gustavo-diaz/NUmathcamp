{
  "hash": "ec08c1b5c4bb77bf49791b0787d3f327",
  "result": {
    "markdown": "---\ntitle: \"Tidyverse II\"\nauthor: \"Aven Peters\"\nformat: html\nembed-resources: true\nexecute:\n  freeze: true\n---\n\n\n## Finding and loading data\n\nWhere do we find publicly available social science data?\n\n-   [ICPSR](https://www.icpsr.umich.edu/web/pages/)\n\n-   [IPUMS](https://www.ipums.org/)\n\n-   Websites of large/commonly used data sets (GSS, ANES, NLSY, etc.)\n\n-   Government open data portals (e.g., the [Chicago Data Portal](https://data.cityofchicago.org/))\n\nTo illustrate how to work with a relatively large, publicly available data set,\nI've created copies of the Department of Education's [College Scorecard](https://collegescorecard.ed.gov/data) data in different formats. We'll\nbe using the institution-level data set, so each row will be a college/university\nin the U.S. Because these files are large and not confidential/sensitive, I've put\nthem and this script on [this Google Drive](https://drive.google.com/drive/folders/1_9--Ti_4zurLFFSIzdHNNJgMLDHww_yo?usp=sharing).\n\n### Functions for reading in data\n\nFirst, let's load the packages we need today. It's a good practice to do this at the top of our Quarto document/R script.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\n# install.packages(\"haven\") # remove the # to run\n\nlibrary(haven)\n```\n:::\n\n\n| File Type                    | R function(s)      | Packages          |\n|------------------------------|--------------------|-------------------|\n| Comma separated values (CSV) | read.csv, read_csv | base R, tidyverse |\n| Excel file (XLS, XLSX)       | read_excel         | tidyverse         |\n| Stata data file (DTA)        | read_dta           | haven             |\n| SPSS data file (SAV)         | read_sav           | haven             |\n| SAS transport file (XPT)     | read_sas           | haven             |\n| R data file (RDS)            | readRDS            | base R            |\n\nRegardless of the data type, these functions will interpret the file name **relative to your working directory.** If the data file is saved in your working directory, you just need the name of the data file. Otherwise, you will have to specify a longer file path.\n\nExample:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv(\"data/Most-Recent-Cohorts-Institution.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 6484 Columns: 3305\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2380): OPEID, OPEID6, INSTNM, CITY, STABBR, ZIP, ACCREDAGENCY, INSTURL,...\ndbl  (850): UNITID, SCH_DEG, HCM2, MAIN, NUMBRANCH, PREDDEG, HIGHDEG, CONTRO...\nlgl   (75): LOCALE2, UG, UGDS_WHITENH, UGDS_BLACKNH, UGDS_API, UGDS_AIANOLD,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndata_sav <- read_sav(\"data/Most-Recent-Cohorts-Institution.sav\")\n\ndata_xpt <- read_xpt(\"data/Most_Recent_Cohorts_Institution.xpt\")\n```\n:::\n\n\n::: callout-tip\n### Exercise\n\nRead in the file \"Most-Recent-Cohorts-Institution.dta\".\n:::\n\nNotice that all of the dataframes have the same dimensions. That's because they're the same data set, just saved in different formats. To be economical, I'm going to delete the extra dataframes. Then I'll examine the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(data_sav, data_xpt) \n\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3,305\n  UNITID OPEID    OPEID6 INSTNM   CITY  STABBR ZIP   ACCREDAGENCY INSTURL NPCURL\n   <dbl> <chr>    <chr>  <chr>    <chr> <chr>  <chr> <chr>        <chr>   <chr> \n1 100654 00100200 001002 Alabama… Norm… AL     35762 Southern As… www.aa… www.a…\n2 100663 00105200 001052 Univers… Birm… AL     3529… Southern As… https:… https…\n3 100690 02503400 025034 Amridge… Mont… AL     3611… Southern As… https:… https…\n4 100706 00105500 001055 Univers… Hunt… AL     35899 Southern As… www.ua… finai…\n5 100724 00100500 001005 Alabama… Mont… AL     3610… Southern As… www.al… www.a…\n6 100751 00105100 001051 The Uni… Tusc… AL     3548… Southern As… www.ua… finan…\n# ℹ 3,295 more variables: SCH_DEG <dbl>, HCM2 <dbl>, MAIN <dbl>,\n#   NUMBRANCH <dbl>, PREDDEG <dbl>, HIGHDEG <dbl>, CONTROL <dbl>,\n#   ST_FIPS <dbl>, REGION <dbl>, LOCALE <dbl>, LOCALE2 <lgl>, LATITUDE <dbl>,\n#   LONGITUDE <dbl>, CCBASIC <dbl>, CCUGPROF <dbl>, CCSIZSET <dbl>, HBCU <dbl>,\n#   PBI <dbl>, ANNHI <dbl>, TRIBAL <dbl>, AANAPII <dbl>, HSI <dbl>,\n#   NANTI <dbl>, MENONLY <dbl>, WOMENONLY <dbl>, RELAFFIL <dbl>,\n#   ADM_RATE <dbl>, ADM_RATE_ALL <dbl>, SATVR25 <dbl>, SATVR75 <dbl>, …\n```\n:::\n:::\n\n\nThere are lots of variables! Let's focus on three: average faculty salary, 6-year completion rate among Pell grant recipients, and region.\n\n::: callout.tip\n### Exercise\n\nCreate a column with only the following columns: AVGFACSAL, C150_4_PELL, REGION.\n:::\n\n\n::: {.cell}\n\n:::\n\n\n## Missing data\n\nReal data sets almost always have at least some missing values. This can occur for a variety of reasons--sometimes a response to a survey question is missing because the respondent refused to answer it, but sometimes it's missing because the respondent never saw the question in the first place (because the question was inapplicable to them, because they stopped taking the survey partway through, or because a random sample of respondents were selected to see the question). Sometimes, variables are not marked as missing in our data, but we recode them as missing because their values are illogical or hard to interpret.\n\nIn publicly available data sets, missing values are represented by many different values. Sometimes a missing value is represented by a dot or the word \"NULL\"; other times, it is a number like -1, 99, 999, etc. The same variable can have multiple missing codes; often, one code will represent a survey response of \"Don't know,\" and another will represent a response of \"Refused.\" If we simply ignored these missing codes, we might get error messages--or worse, incorrect answers that *don't* raise error messages.\n\nSuppose we have the following table in the codebook.\n\n| Response   | Value | Frequency |\n|------------|-------|-----------|\n| Yes        | 1     | 0.45      |\n| No         | 2     | 0.35      |\n| Don't Know | 7     | 0.15      |\n| Refused    | 9     | 0.05      |\n\nIf we naively took the mean of this variable, we would get 2.65, which clearly makes no sense for the substantive meaning of the variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1*0.45 + 2*0.35 + 7*0.15 + 9*0.05\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.65\n```\n:::\n:::\n\n\nTo prevent issues like this, it's important to recode missing values as NA, which is what R recognizes as missing data. In the dataframe we just loaded, our missing values are already coded as NA, so we can skip this step.\n\nA full treatment of missing data is beyond the scope of today's class. However, you should know how to do two simple tasks. First, you should know how much missing data you have. Here's a simple way to check.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(selection$AVGFACSAL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2596\n```\n:::\n\n```{.r .cell-code}\nsum(is.na(selection$C150_4_PELL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4300\n```\n:::\n\n```{.r .cell-code}\nsum(is.na(selection$REGION))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nWe have quite a bit of missing data for faculty salary, and even more for Pell grant recipient completion rate. We happen not to have any missing data for region.\n\nNext, you should know how to remove all rows of your data set with missing values for the variables you're interested in. This is called **listwise deletion**, and it's not always the right choice, but it's very common in social science research. Here are two ways to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# method 1\nselection_complete <- selection %>%\n  filter(!is.na(AVGFACSAL) & !is.na(C150_4_PELL) & !is.na(REGION))\n\nnrow(selection_complete) # check how many rows we have left\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2148\n```\n:::\n\n```{.r .cell-code}\n# method 2\nselection_complete <- selection %>%\n  na.omit() # omit all rows with missing values in any variables in the dataframe;\n# can also specify specific variables we'd like to delete\n\nnrow(selection_complete) # check how many rows we have left again\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2148\n```\n:::\n:::\n\n\nEncouragingly, we get the same number of rows in the complete dataframe using both methods.\n\n::: callout-tip\n### Exercise\n\n1.  Try to remove all rows of selection that have missing values for faculty salary, but keep rows with missing values for Pell recipient completion rate.\n2.  Do universities in different regions of the U.S. have different amounts of missing data? Why might this be?\n:::\n\n## Recoding variables\n\nBefore we do any data analysis, we will need to prepare our variables by recoding them. This is especially true for categorical variables. Region in this data set is a good example. From the codebook, we have the following information.\n\n| Region               | Value |\n|----------------------|-------|\n| U.S. Service Schools | 0     |\n| New England          | 1     |\n| Mid East             | 2     |\n| Great Lakes          | 3     |\n| Plains               | 4     |\n| Southeast            | 5     |\n| Southwest            | 6     |\n| Rocky Mountains      | 7     |\n| Far West             | 8     |\n| Outlying Areas       | 9     |\n\nSuppose we wanted to combine some of these regions. We could combine New England and Mid East into an \"East\" category, group Great Lakes and Plains into a \"Midwest\" category, keep \"Southeast\" as its own category, put Southwest, Rocky Mountains, and Far West into a \"West\" category, and collapse the remaining regions (U.S. Service Schools and Outlying Areas) into an \"Other region\" category.\n\nThe case_when function is ideal for this task. Here's how we might do it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete <- selection_complete %>%\n  mutate(region_rec = case_when(REGION %in% c(1,2) ~ \"East\",\n                                REGION %in% c(3,4) ~ \"Midwest\",\n                                REGION == 5 ~ \"South\",\n                                REGION %in% c(6:8) ~ \"West\",\n                                TRUE ~ \"Other\"))\n```\n:::\n\n\nWhy is the condition for the last line \"TRUE\"? Case_when reads each line sequentially,\nand assigns the value for the **first** statement that is true. When REGION is between\n1 and 8, at least one of the first four conditions must hold. When evaluating case_when,\nR only goes to the last line when none of the first four conditions have held. This\ncould only possibly happen if REGION was 0 or 9. By writing \"TRUE,\" we are effectively\nsaying, \"If you've gotten to this point, assign the value 'Other' no matter what.\"\nOf course, we could also use a more specific condition for this last line--TRUE\nis just often simpler to type and makes sure we don't leave out any data.\n\nWhat if we only cared whether or not a school was in the South? We could create\na simpler binary variable for this with case_when like this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete <- selection_complete %>%\n  mutate(south = case_when(REGION == 5 ~ 1,\n                           TRUE ~ 0))\n```\n:::\n\n\nThis code is equivalent to the if_else function we learned about yesterday. Using that\nfunction, we could write the following.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete <- selection_complete %>%\n  mutate(south = if_else(REGION == 5, 1, 0))\n```\n:::\n\n\n:::{.callout-tip}\n### Exercise\nCreate a \"west\" variable indicating whether a university is in the West of the U.S.\nFind the mean of this variable. What does the mean represent substantively?\n:::\n\n## More data visualization\n\nIn addition to histograms, you should know how to create and interpret a scatterplot.\nThe syntax for a scatterplot is similar to that for the histogram we created yesterday.\nLet's plot faculty salary on the X-axis and Pell recipient completion rate on the Y-axis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete %>%\n  ggplot(aes(x = AVGFACSAL, y = C150_4_PELL)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](03_tidy2_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWhat do we learn from this scatterplot?\n\n:::{.callout-tip}\n### Exercise\nReferencing yesterday's material, relabel the axes and add a meaningful title.\n:::\n\nWe might wonder if there's variation in this relationship by region. Let's explore\nthis in two ways. First, we'll allow the color of the points to indicate the region\nof the university.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete %>%\n  ggplot(aes(x = AVGFACSAL, y = C150_4_PELL, col = region_rec)) +\n  geom_point() +\n  labs(x = \"Average faculty salary (monthly)\", y = \"6-Year graduation rate among Pell Grant recipients\", col = \"Region\", title = \"Pell grant recipient graduation rate by faculty salary\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](03_tidy2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nIt's hard to see obvious patterns on this plot. Subjectively, it seems like the \"Other\"\nregion schools tend to have lower faculty salaries in general, and those salaries\ndon't seem very predictive of graduation rates among Pell grant recipients. However,\nwe would need better tools to test this conjecture.\n\nA clearer way to see differences in the relationship between faculty salary and graduation\nrates by region is to use a facet wrap. This will create five separate scatterplots,\none for each region.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselection_complete %>%\n  ggplot(aes(x = AVGFACSAL, y = C150_4_PELL)) +\n  geom_point() +\n  labs(x = \"Average faculty salary (monthly)\", y = \"6-Year graduation rate among Pell Grant recipients\", title = \"Pell grant recipient graduation rate by faculty salary\") +\n  theme_minimal() +\n  facet_wrap(~region_rec)\n```\n\n::: {.cell-output-display}\n![](03_tidy2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nHow would you interpret these plots?\n\n## Additional topics: working with dates\n\nTo explore these topics, we'll use another built-in data set. But first, we'll need\nto load an additional package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"nycflights13\")\nlibrary(nycflights13)\n```\n:::\n\n\nWe'll use the flights data set, which contains information about all flights from\nNew York airports in 2013. First, let's take a look at the first few rows of data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n\nThe last column of this data set indicates the date and time of the flight.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- flights %>%\n  mutate(flight_date = date(time_hour))\n```\n:::\n\n\nOnce we have converted this variable into a date, we can use other functions in\nlubridate to extract the year, month, and day of each date. We can also compute the\ntime between two dates in days (or any other unit of time). Here are some examples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyear(flights$flight_date[500])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2013\n```\n:::\n\n```{.r .cell-code}\nday(flights$flight_date[500])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\nmonth(flights$flight_date[500])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\nint <- interval(start = flights$flight_date[1], end = flights$flight_date[10000])\nsecs <- int_length(int) # interval length in seconds\ndays <- int_length(int)/(60*60*24) # divide to get interval length in days\n\nsecs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 950400\n```\n:::\n\n```{.r .cell-code}\ndays\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11\n```\n:::\n:::\n\nThis is just a quick sampling of the lubridate package. For more information, check out\nthe lubridate website [here](https://lubridate.tidyverse.org/index.html).\n",
    "supporting": [
      "03_tidy2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}