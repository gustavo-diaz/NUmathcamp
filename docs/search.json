[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math Camp",
    "section": "",
    "text": "This is the website for the 2024 Social Science Math Camp, hosted by the Departments of Political Science and Sociology at Northwestern University. The purpose of Math Camp is to give you a chance to brush up on concepts and skills that underlie the practice of quantitative data analysis in the social sciences.\nOur schedule features math in the morning and statistical programming in the afternoon. During lunch, we will also have a chance to meet faculty and graduate students and have more informal conversations about the role of methods training in graduate school.\n\n\n\n   September 16 – 20\n   9:00 AM – 4:00 PM\n   Scott Hall 212",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Math Camp",
    "section": "",
    "text": "This is the website for the 2024 Social Science Math Camp, hosted by the Departments of Political Science and Sociology at Northwestern University. The purpose of Math Camp is to give you a chance to brush up on concepts and skills that underlie the practice of quantitative data analysis in the social sciences.\nOur schedule features math in the morning and statistical programming in the afternoon. During lunch, we will also have a chance to meet faculty and graduate students and have more informal conversations about the role of methods training in graduate school.\n\n\n\n   September 16 – 20\n   9:00 AM – 4:00 PM\n   Scott Hall 212",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Math Camp",
    "section": "Schedule",
    "text": "Schedule\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                Day\n                Date\n                Morning\n                Afternoon\n              \n        \n        \n        \n                \n                  1\n                  September 16\n                  Notation, sets, functions\n                  R and RStudio          \n                \n                \n                  2\n                  September 17\n                  Matrices                 \n                  Tidyverse I            \n                \n                \n                  3\n                  September 18\n                  Calculus I               \n                  Tidyverse II           \n                \n                \n                  4\n                  September 19\n                  NO MEETING               \n                  NA                     \n                \n                \n                  5\n                  September 20\n                  Calculus II              \n                  Sampling and simulation",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "math/01_notation.html",
    "href": "math/01_notation.html",
    "title": "Notation, Sets, and Functions",
    "section": "",
    "text": "A great deal of quantitave empirical research in the social sciences and statistics textbooks use notation extensively. Notation is useful to write about general concepts or ideas that apply to a broad range of settings. The downside is that notation makes things harder to read.\nThis section introduces common notation practices in the social sciences that will help you in both in methods courses and when reading/writing papers. Usage may vary across fields and over time, but becoming familiar with general uses may still help you understand the deviations.",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "r/04_sampling.html",
    "href": "r/04_sampling.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD.",
    "crumbs": [
      "Programming",
      "4. Sampling and simulation"
    ]
  },
  {
    "objectID": "r/02_tidy1.html",
    "href": "r/02_tidy1.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD.",
    "crumbs": [
      "Programming",
      "2. Tidyverse I"
    ]
  },
  {
    "objectID": "math/04_calc2.html",
    "href": "math/04_calc2.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD.",
    "crumbs": [
      "Math",
      "4. Calculus II"
    ]
  },
  {
    "objectID": "math/02_matrices.html",
    "href": "math/02_matrices.html",
    "title": "Matrices",
    "section": "",
    "text": "Matrices are rectangular collections of numbers, meaning they are arranged by rows and columns. Learning about matrices is important because most of the data that social scientists use is rectangular data. The rest, less structured data, is eventually converted to a rectangular format before analysis.\nMoreover, matrix algebra is the working engine behind regression models, a cornerstone tool for data analysis. When R and other software quickly convert rectangular data into a vector of regression coefficient, what goes under the hood is usually a bunch of matrix algebra.\n\n\n\n\nA single number (for example, 12) is referred to as a scalar.\n\\[\na = 12\n\\]\n\n\n\nWe can put several scalars together to make a vector. Vectors are usually denoted with an arrow on top, although social scientist tend to forgo this convention. Here is an example:\n\\[\n\\overrightarrow b =\n\\begin{bmatrix}\n  12 \\\\\n  14 \\\\\n  15\n\\end{bmatrix}\n\\]\nSince this is a column of numbers, we refer to it as a column vector.\nOf course, we can also have row vectors:\n\\[\n\\overrightarrow c = \\begin{bmatrix}\n  12 & 14 & 15\n\\end{bmatrix}\n\\]\nNote that we use brackets \\([ ... ]\\) to demarcate vectors and matrices.\nIn R, we can construct vectors with the the c() function to combine elements (the c stands for concatenate):\n\nc(5, 25, -2, 1)\n\n[1]  5 25 -2  1\n\n\nWe can also create vectors that follow a pattern with the : operator or the seq() function:\n\n10:20\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nseq(from = 3, to = 27, by = 3)\n\n[1]  3  6  9 12 15 18 21 24 27\n\n\n\n\n\n\n\n\nThe summation operator \\(\\sum\\) (i.e., the uppercase Sigma letter) lets us perform an operation on a sequence of numbers, which is often but not always a vector.\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & -1\n\\end{bmatrix}\\]\nWe can then calculate the sum of the first three elements of the vector, which is expressed as follows: \\[\\sum_{i=1}^3 d_i\\]\nThen we do the following math: \\[12+7+(-2)=17\\]\nIt is also common to use \\(n\\) in the superscript to indicate that we want to sum up to the very last element:\n\\[\n\\sum_{i=1}^n d_i = 12 + 7 + (-2) + 3 + (-1) = 19\n\\]\nWe can perform these operations using the sum() function in R:\n\nd = c(12, 7, -2, 3, -1)\n\n\nsum(d)\n\n[1] 19\n\n\n\nsum(d[1:3])\n\n[1] 17\n\n\n\nsum(d)\n\n[1] 19\n\n\n\n\n\nThe product operator \\(\\prod\\) (uppercase Pi) can also perform operations over a sequence of elements in a vector. Recall our previous vector:\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & 1\n\\end{bmatrix}\\]\nWe might want to calculate the product of all its elements, which is expressed as follows: \\[\\prod_{i=1}^n d_i = 12 \\cdot 7 \\cdot (-2) \\cdot 3 \\cdot (-1) = 504\\]\nIn R, we can compute products using the prod() function:\n\nprod(d)\n\n[1] 504\n\n\n\n\n\n\n\n\n\n\nWe can append vectors together to form a matrix:\n\\[A = \\begin{bmatrix}\n12 & 14 & 15 \\\\\n115 & 22 & 127 \\\\\n193 & 29 & 219\n\\end{bmatrix}\\]\nThe number of rows and columns of a matrix constitute the dimensions of the matrix. The first number is the number of rows (“r”) and the second number is the number of columns (“c”) in the matrix. The order of dimensions never changes.\nMatrix \\(A\\) above, for example, is a \\(3 \\times 3\\) matrix. Sometimes we’d refer to it as \\(A_{3 \\times 3}\\). We commonly use capital letters to represent matrices. Sometimes, vectors and matrices are further denoted with bold font.\n\n\nThere are different ways to create matrices in R. One of the simplest is via rbind() or cbind(), which paste vectors together (either by rows or by columns):\n\n# Create some vectors\nvector1 = 1:4\nvector2 = 5:8\nvector3 = 9:12\nvector4 = 13:16\n\n\n# Using rbind(), each vector will be a row \nrbind_mat = rbind(vector1, vector2, vector3, vector4)\nrbind_mat\n\n        [,1] [,2] [,3] [,4]\nvector1    1    2    3    4\nvector2    5    6    7    8\nvector3    9   10   11   12\nvector4   13   14   15   16\n\n\n\n# Using cbind(), each vector will be a column\ncbind_mat = cbind(vector1, vector2, vector3, vector4)\ncbind_mat\n\n     vector1 vector2 vector3 vector4\n[1,]       1       5       9      13\n[2,]       2       6      10      14\n[3,]       3       7      11      15\n[4,]       4       8      12      16\n\n\nAn alternative is to use to properly named matrix() function. The basic syntax is matrix(data, nrow, ncol, byrow):\n\ndata is the input vector which becomes the data elements of the matrix.\nnrow is the number of rows to be created.\nncol is the number of columns to be created.\nbyrow is a logical clue. If TRUE then the input vector elements are arranged by row. By default (FALSE), elements are arranged by column.\n\nLet’s see some examples:\n\n# Elements are arranged sequentially by row.\nM = matrix(c(1:12), nrow = 4, byrow = T)\nM\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n\n\n# Elements are arranged sequentially by column (byrow = F by default).\nN = matrix(c(1:12), nrow = 4)\nN\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\n\n\n\n\n[CONTINUE HERE]\nHow do we refer to specific elements of the matrix? For example, matrix \\(A\\) is an \\(m\\times n\\) matrix where \\(m=n=3\\). This is sometimes called a square matrix.\nMore generally, matrix \\(B\\) is an \\(m\\times n\\) matrix where the elements look like this: \\[B=\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & \\ldots & b_{1n} \\\\\nb_{21} & b_{22} & b_{23} & \\ldots & b_{2n} \\\\\n\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\nb_{m1} & b_{m2} & b_{m3} & \\ldots & b_{mn}\n\\end{bmatrix}\\]\nThus \\(b_{23}\\) refers to the second unit down and third across. More generally, we refer to row indices as \\(i\\) and to column indices as \\(j\\).\nIn R, we can access a matrix’s elements using square brackets:\n\n# In matrix N, access the element at 1st row and 3rd column.\nN[1,3]\n\n[1] 9\n\n\n\n# In matrix N, access the element at 4th row and 2nd column.\nN[4,2]\n\n[1] 8\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen trying to identify a specific element, the first subscript is the element’s row and the second subscript is the element’s column (always in that order).\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn R, indexing is 1-based, meaning that the first element of a vector, matrix, or any other data structure is accessed with index 1. In other programming tools such as Python, indexing is 0-based, meaning that the first element of a list, array, or any other data structure is accessed with index 0.\n\n# Create a 2x2 matrix in R\nmatrix_A = matrix(1:4, nrow = 2, ncol = 2)\n\n# Access the element in the first row, first column\nelement = matrix_A[1, 1]  # This will return 1\n\n# Create a list in Python\nvector = [10, 20, 30, 40]\n\n# Access the first element\nfirst_element = vector[0]  # This will return 10\nimport numpy as np\n\n# Create a 2x2 matrix in Python with NumPy\nmatrix_A = np.array([[1, 2], [3, 4]])\n\n# Access the element in the first row, first column\nelement = matrix_A[0, 0]  # This will return 1\n\n\n\n\n\n\n\n\n\nAddition and subtraction are straightforward operations.\nMatrices must have exactly the same dimensions for both of these operations.\nWe add or subtract each element with the corresponding element from the other matrix.\nThis is expressed as follows:\n\n\\[A \\pm B=C\\]\n\\[c_{ij}=a_{ij} \\pm b_{ij} \\text{ }\\forall i,j\\]\n\\[\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\pm\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13}\\\\\nb_{21} & b_{22} & b_{23}\\\\\nb_{31} & b_{32} & b_{33}\n\\end{bmatrix}\\] \\[=\\] \\[\\begin{bmatrix}\na_{11}\\pm b_{11} & a_{12}\\pm b_{12} & a_{13}\\pm b_{13}\\\\\na_{21}\\pm b_{21} & a_{22}\\pm b_{22} & a_{23}\\pm b_{23}\\\\\na_{31}\\pm b_{31} & a_{32}\\pm b_{32} & a_{33}\\pm b_{33}\n\\end{bmatrix}\\]\n\n\nWe start by creating two 2x3 matrices:\n\\[A= \\begin{bmatrix}\n3 & -1 & 2  \\\\\n9 & 4 & 6\n\\end{bmatrix}\\]\n\n# Create two 2x3 matrices.\nmatrix1 = matrix(c(3, 9, -1, 4, 2, 6), nrow = 2)\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\nAnd \\[B= \\begin{bmatrix}\n5 & 2 & 0  \\\\\n9 & 3 & 4\n\\end{bmatrix}\\]\n\nmatrix2 = matrix(c(5, 2, 0, 9, 3, 4), nrow = 2)\nmatrix2\n\n     [,1] [,2] [,3]\n[1,]    5    0    3\n[2,]    2    9    4\n\n\nWe can simply use the + and - operators for addition and substraction:\n\nmatrix1 + matrix2\n\n     [,1] [,2] [,3]\n[1,]    8   -1    5\n[2,]   11   13   10\n\n\n\nmatrix1 - matrix2\n\n     [,1] [,2] [,3]\n[1,]   -2   -1   -1\n[2,]    7   -5    2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n(Use code for one of these and do the other one by hand!)\n1) Calculate \\(A + B\\)\n\\[A= \\begin{bmatrix}\n1 & 0 \\\\\n-2 & -1\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n5 & 1 \\\\\n2 & -1\n\\end{bmatrix}\\]\n\n2) Calculate \\(A - B\\)\n\\[A= \\begin{bmatrix}\n6 & -2 & 8 & 12 \\\\\n4 & 42 & 8 & -6\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n18 & 42 & 3 & 7 \\\\\n0 & -42 & 15 & 4\n\\end{bmatrix}\\]\n\n\n\n\n\n\nScalar multiplication is very intuitive. As we know, a scalar is a single number. We multiply each value in the matrix by the scalar to perform this operation.\nFormally, this is expressed as follows: \\[A =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\] \\[cA =\n\\begin{bmatrix}\nca_{11} & ca_{12} & ca_{13}\\\\\nca_{21} & ca_{22} & ca_{23}\\\\\nca_{31} & ca_{32} & ca_{33}\n\\end{bmatrix}\\]\nIn R, all we need to do is take an established matrix and multiply it by some scalar:\n\n# matrix1 from our previous example\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix1 * 3\n\n     [,1] [,2] [,3]\n[1,]    9   -3    6\n[2,]   27   12   18\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate \\(2\\times A\\) and \\(-3 \\times B\\). Again, do one by hand and the other one using R.\n\\[A= \\begin{bmatrix}\n    1 & 4 & 8 \\\\\n    0 & -1 & 3\n    \\end{bmatrix}\\] \\[ B = \\begin{bmatrix}\n    -15 & 1 & 5 \\\\\n    2 & -42 & 0 \\\\\n    7 & 1 & 6\n    \\end{bmatrix}\\]\n\n\n\n\n\n\nMultiplying matrices is slightly trickier than multiplying scalars.\nTwo matrices must be conformable for them to be multiplied together. This means that the number of columns in the first matrix equals the number of rows in the second.\nWhen multiplying \\(A \\times B\\), if \\(A\\) is \\(m \\times n\\), \\(B\\) must have \\(n\\) rows.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe conformability requirement never changes. Before multiplying anything, check to make sure the matrices are indeed conformable.\n\n\n\nThe resulting matrix will have the same number of rows as the first matrix and the number of columns in the second. For example, if \\(A\\) is \\(i \\times k\\) and \\(B\\) is \\(k \\times j\\), then \\(A \\times B\\) will be \\(i \\times j\\).\n\n\nWhich of the following can we multiply? What will be the dimensions of the resulting matrix? \\[\\begin{aligned}\nB_{4 \\times 1}=\n\\begin{bmatrix}\n2 \\\\\n3\\\\\n4\\\\\n1\n\\end{bmatrix}\nM_{3 \\times 3} =\n\\begin{bmatrix}\n1 & 0 & 2\\\\\n1 & 2 & 4\\\\\n2 & 3 & 2\n\\end{bmatrix}\nL_{2 \\times 3} =\n\\begin{bmatrix}\n6 & 5 & -1\\\\\n1 & 4 & 3\n\\end{bmatrix}\n\\end{aligned}\\]\nThe only valid multiplication based on the provided matrices is \\(L \\times M\\), which results in a \\(2 \\times 3\\) matrix.\nWhy can’t we multiply in the opposite order?\nThe non-commutative property of matrix multiplication is a fundamental aspect in matrix algebra. The multiplication of matrices is sensitive to the order in which the matrices are multiplied due to the requirements of dimensional compatibility, the resulting dimensions, and the computation process itself.\n\n\n\n\n\n\nWarning\n\n\n\nWhen multiplying matrices, order matters. Even if multiplication is possible in both directions, in general \\(AB \\neq BA\\).\n\n\n\n\n\nMultiply each row by each column, summing up each pair of multiplied terms.\n\n\n\n\n\n\n\nTip\n\n\n\nThis is sometimes to referred to as the “dot product,” where we multiply matching members, then sum up.\n\n\n\nThe element in position \\(ij\\) is the sum of the products of elements in the \\(i\\)th row of the first matrix (\\(A\\)) and the corresponding elements in the \\(j\\)th column of the second matrix (\\(B\\)). \\[c_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}\\]\n\n\n\n\nSuppose a company manufactures two kinds of furniture: chairs and sofas.\n\nA chair costs $100 for wood, $270 for cloth, and $130 for feathers.\nEach sofa costs $150 for wood, $420 for cloth, and $195 for feathers.\n\n\n\n\n\nChair\nSofa\n\n\n\n\nWood\n100\n150\n\n\nCloth\n270\n420\n\n\nFeathers\n130\n195\n\n\n\nThe same information about unit cost (\\(C\\)) can be presented as a matrix.\n\\[C = \\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\\]\nNote that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).\n\nNow, suppose that the company will produce 45 chairs and 30 sofas this month. This production quantity can be represented in the following table, and also as a 2 x 1 matrix (\\(Q\\)):\n\n\n\nProduct\nQuantity\n\n\n\n\nChair\n45\n\n\nSofa\n30\n\n\n\n\\[Q = \\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix}\\]\nWhat will be the company’s total cost? The “total expenditure” is equal to the “unit cost” times the “production quantity” (the number of units).\nThe total expenditure (\\(E\\)) for each material this month is calculated by multiplying these two matrices.\n\\[\\begin{aligned} E = CQ =\n\\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\n\\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix} =\n\\begin{bmatrix}\n(100)(45) + (150)(30) \\\\\n(270)(45) + (420)(30) \\\\\n(130)(45) + (195)(30)\n\\end{bmatrix} =\n\\begin{bmatrix}\n9,000 \\\\\n24,750 \\\\\n11,700\n\\end{bmatrix}\n\\end{aligned}\\]\nMultiplying the 3x2 Cost matrix (\\(C\\)) times the 2x1 Quantity matrix (\\(Q\\)) yields the 3x1 Expenditure matrix (\\(E\\)).\nAs a result of this matrix multiplication, we determine that this month the company will incur expenditures of:\n\n$9,000 for wood\n$24,750 for cloth\n$11,700 for feathers.\n\n\n\n\nBefore attempting matrix multiplication, we must make sure the matrices are conformable (as we do for our manual calculations).\nThen we can multiply our matrices together using the %*% operator.\n\nC = matrix(c(100, 270, 130, 150, 420, 195), nrow = 3)\nC\n\n     [,1] [,2]\n[1,]  100  150\n[2,]  270  420\n[3,]  130  195\n\n\n\nQ = matrix(c(45, 30), nrow = 2)\nQ\n\n     [,1]\n[1,]   45\n[2,]   30\n\n\n\nC %*% Q\n\n      [,1]\n[1,]  9000\n[2,] 24750\n[3,] 11700\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have a missing value or NA in one of the matrices you are trying to multiply (something we will discuss in further detail in the next module), you will have NAs in your resulting matrix.\n\n\n\n\n\n\n\n\nAddition and subtraction:\n\nAssociative: \\((A \\pm B) \\pm C = A \\pm (B \\pm C)\\)\nCommunicative: \\(A \\pm B = B \\pm A\\)\n\nMultiplication:\n\n\\(AB \\neq BA\\)\n\\(A(BC) = (AB)C\\)\n\\(A(B+C) = AB + AC\\)\n\\((A+B)C = AC + BC\\)\n\n\n\n\n\n\nSquare matrix\n\\[\nA = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{bmatrix}\n\\]\n\nIn a square matrix, the number of rows equals the number of columns (\\(m=n\\)):\nThe diagonal of a matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix, as in $ d(A)=[1,5,9] $. Diagonals are particularly useful in square matrices.\nThe trace of a matrix, denoted as \\(tr(A)\\), is the sum of the diagonal elements of the matrix. \\(tr(A) = 1+5+9 = 15\\)\n\nDiagonal matrix:\n\nIn a diagonal matrix, all of the elements of the matrix that are not on the diagonal are equal to zero. \\[\nD = \\begin{bmatrix}\n4 & 0 & 0 \\\\\n0 & 5 & 0 \\\\\n0 & 0 & 6\n\\end{bmatrix}\n\\]\n\nScalar matrix:\n\nA scalar matrix is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we’re really only concerned with one scalar (or element) held in the diagonal.\n\n\\[\nS = \\begin{bmatrix}\n7 & 0 & 0 \\\\\n0 & 7 & 0 \\\\\n0 & 0 & 7\n\\end{bmatrix}\n\\]\nIdentity matrix:\n\\[\nI = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\n\nThe identity matrix is a scalar matrix with all of the diagonal elements equal to one.\nRemember that, as with all diagonal matrices, the off-diagonal elements are equal to zero.\nThe capital letter \\(I\\) is reserved for the identity matrix. For convenience, a 3x3 identity matrix can be denoted as \\(I_3\\).\n\n\n\n\nThe transpose is the original matrix with the rows and the columns interchanged.\nThe notation is either \\(J'\\) (“J prime”) or \\(J^T\\) (“J transpose”).\n\\[J =\n\\begin{bmatrix}\n4 & 5\\\\\n3 & 0\\\\\n7 & -2\n\\end{bmatrix}\\]\n\\[J' = J^T =\n\\begin{bmatrix}\n4 & 3 & 7 \\\\\n5 & 0 & -2\n\\end{bmatrix}\\]\nIn R, we use t() to get the transpose.\n\nJ = matrix(c(4, 3, 7, 5, 0, -2), ncol = 2)\nJ\n\n     [,1] [,2]\n[1,]    4    5\n[2,]    3    0\n[3,]    7   -2\n\n\n\nt(J)\n\n     [,1] [,2] [,3]\n[1,]    4    3    7\n[2,]    5    0   -2\n\n\n\n\n\n\nJust like a number has a reciprocal, a matrix has an inverse.\nWhen we multiply a matrix by its inverse we get the identity matrix (which is like “1” for matrices).\n\n\\[A × A^{-1} = I\\]\n\nThe inverse of A is \\(A^{-1}\\) only when:\n\n\\[AA^{-1} = A^{-1}A = I\\]\n\nSometimes there is no inverse at all.\n\n\n\n\n\n\n\nNote\n\n\n\nFor now, don’t worry about calculating the inverse of a matrix manually. This is the type of task we use R for.\n\n\n\nIn R, we use the solve() function to calculate the inverse of a matrix:\n\n\nA = matrix(c(3, 2, 5, 2, 3, 2, 5, 2, 4), ncol = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    3    2    5\n[2,]    2    3    2\n[3,]    5    2    4\n\n\n\nsolve(A)\n\n            [,1]        [,2]       [,3]\n[1,] -0.29629630 -0.07407407  0.4074074\n[2,] -0.07407407  0.48148148 -0.1481481\n[3,]  0.40740741 -0.14814815 -0.1851852\n\n\n\n\n\n\nA system of equations can be represented by an augmented matrix.\nSystem of equations: \\[{\\color{red}{3}}x + {\\color{green}{6}}y = {\\color{blue}{12}}\\] \\[{\\color{red}{5}}x + {\\color{green}{10}}y = {\\color{blue}{25}}\\]\nIn an augmented matrix, each row represents one equation in the system and each column represents a variable or the constant terms. \\[\\begin{bmatrix}\n{\\color{red}{3}} & {\\color{green}{6}} & {\\color{blue}{12}}\\\\\n{\\color{red}{5}} & {\\color{green}{10}} & {\\color{blue}{25}}\n\\end{bmatrix}\\]\n\n\n\n\n\nWe can use the logic above to calculate estimates for our ordinary least squares (OLS) models.\nOLS is a linear regression technique used to find the best-fitting line for a set of data points (observations) by minimizing the residuals (the differences between the observed and predicted values).\nWe minimize the sum of the squared errors.\n\n\n\n\nSuppose, for example, we have a sample consisting of \\(n\\) observations.\nThe dependent variable is denoted as an \\(n \\times1\\) column vector.\n\n\\[Y = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\\]\n\n\n\n\nSuppose there are \\(k\\) independent variables and a constant term, meaning \\(k+1\\) columns and \\(n\\) rows.\nWe can represent these variables as an \\(n \\times (k+1)\\) matrix, expressed as follows:\n\n\\[X= \\begin{bmatrix}\n1 & x_{11} & \\dots & x_{1k} \\\\\n1 & x_{21} & \\dots & x_{2k} \\\\\n\\vdots & \\vdots & \\dots & \\vdots \\\\\n1 & x_{n1} & \\dots & x_{nk}\n\\end{bmatrix}\\]\n\n\\(x_{ij}\\) is the \\(i\\)-th observation of the \\(j\\)-th independent variable.\n\n\n\n\n\nLet’s say we have 173 observations (n = 173) and 2 IVs (k = 3).\nThis can be expressed as the following linear equation: \\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon\\]\nIn matrix form, we have: \\[\\begin{aligned} \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} = \\begin{bmatrix}\n1 & x_{11} & x_{21} \\\\\n1 & x_{21} & x_{22} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_{1173} & x_{2173}\n\\end{bmatrix} \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix} + \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_{173}\n\\end{bmatrix}\\end{aligned} \\]\nAll 173 equations can be represented by: \\[y=X\\beta+\\epsilon\\]\n\n\n\n\n\nWithout getting too much into the mechanics, we can calculate our coefficient estimates with matrix algebra using the following equation:\n\n\\[\\hat{\\beta} = (X'X)^{-1}X'Y\\]\n\nRead aloud, we say “X prime X inverse, X prime Y”.\nThe little hat on our beta (\\(\\hat{\\beta}\\)) signifies that these are estimates.\nRemember, the OLS method is to choose \\(\\hat{\\beta}\\) such that the sum of squared residuals (“SSR”) is minimized.\n\n\n\n\nWe will load the mtcars data set (our favorite) for this example, which contains data about many different car models.\n\n\ncars_df = mtcars\n\n\nNow, we want to estimate the association between hp (horsepower) and wt (weight), our independent variables, and mpg (miles per gallon), our dependent variable.\nFirst, we transform our dependent variable into a matrix, using the as.matrix function and specifying the column of the mtcars data set to create a column vector of our observed values for the DV.\n\n\nY = as.matrix(cars_df$mpg)\nY\n\n      [,1]\n [1,] 21.0\n [2,] 21.0\n [3,] 22.8\n [4,] 21.4\n [5,] 18.7\n [6,] 18.1\n [7,] 14.3\n [8,] 24.4\n [9,] 22.8\n[10,] 19.2\n[11,] 17.8\n[12,] 16.4\n[13,] 17.3\n[14,] 15.2\n[15,] 10.4\n[16,] 10.4\n[17,] 14.7\n[18,] 32.4\n[19,] 30.4\n[20,] 33.9\n[21,] 21.5\n[22,] 15.5\n[23,] 15.2\n[24,] 13.3\n[25,] 19.2\n[26,] 27.3\n[27,] 26.0\n[28,] 30.4\n[29,] 15.8\n[30,] 19.7\n[31,] 15.0\n[32,] 21.4\n\n\n\nNext, we do the same thing for our independent variables of interest, and our constant.\n\n\n# create two separate matrices for IVs\nX1 = as.matrix(cars_df$hp)\nX2 = as.matrix(cars_df$wt)\n\n# create constant column\n\n# bind them altogether into one matrix\nconstant =  rep(1, nrow(cars_df))\nX = cbind(constant, X1, X2)\nX\n\n      constant          \n [1,]        1 110 2.620\n [2,]        1 110 2.875\n [3,]        1  93 2.320\n [4,]        1 110 3.215\n [5,]        1 175 3.440\n [6,]        1 105 3.460\n [7,]        1 245 3.570\n [8,]        1  62 3.190\n [9,]        1  95 3.150\n[10,]        1 123 3.440\n[11,]        1 123 3.440\n[12,]        1 180 4.070\n[13,]        1 180 3.730\n[14,]        1 180 3.780\n[15,]        1 205 5.250\n[16,]        1 215 5.424\n[17,]        1 230 5.345\n[18,]        1  66 2.200\n[19,]        1  52 1.615\n[20,]        1  65 1.835\n[21,]        1  97 2.465\n[22,]        1 150 3.520\n[23,]        1 150 3.435\n[24,]        1 245 3.840\n[25,]        1 175 3.845\n[26,]        1  66 1.935\n[27,]        1  91 2.140\n[28,]        1 113 1.513\n[29,]        1 264 3.170\n[30,]        1 175 2.770\n[31,]        1 335 3.570\n[32,]        1 109 2.780\n\n\n\nNext, we calculate \\(X'X\\), \\(X'Y\\), and \\((X'X)^{-1}\\).\n\n\nDon’t forget to use %*% for matrix multiplication!\n\n\n# X prime X\nXpX = t(X) %*% X\n\n# X prime X inverse\nXpXinv = solve(XpX)\n\n# X prime Y\nXpY = t(X) %*% Y\n\n# beta coefficient estimates\nbhat = XpXinv %*% XpY\nbhat\n\n                [,1]\nconstant 37.22727012\n         -0.03177295\n         -3.87783074",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/03_calc1.html",
    "href": "math/03_calc1.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD.",
    "crumbs": [
      "Math",
      "3. Calculus I"
    ]
  },
  {
    "objectID": "r/01_intro.html",
    "href": "r/01_intro.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD.",
    "crumbs": [
      "Programming",
      "1. Getting started"
    ]
  },
  {
    "objectID": "r/03_tidy2.html",
    "href": "r/03_tidy2.html",
    "title": "Untitled",
    "section": "",
    "text": "This is a placeholder document. Content TBD."
  },
  {
    "objectID": "math/01_notation.html#overview",
    "href": "math/01_notation.html#overview",
    "title": "Notation, Sets, and Functions",
    "section": "",
    "text": "SKKRRTSAAAY",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#conditions",
    "href": "math/01_notation.html#conditions",
    "title": "Notation, Sets, and Functions",
    "section": "2.1 Conditions",
    "text": "2.1 Conditions\nA set is a collection of elements, we use symbols to refer to different parts of the set.\n\n\n\n\n\n\n\n\nNotation\nMeaning\nUse\n\n\n\n\n{\nbracket\nSpecify a set (e.g. {2, 3})\n\n\n\\(\\exists\\)\n“there exists”: true for at least one thing\nSpecify a condition to be satisfied\n\n\n\\(\\forall\\)\n“for all”; true for all elements\nSpecify which elements belong in a set (all that satisfy a criteron)\n\n\n\\(\\exists\\)\n“exists”; there is something true\nSpecify a rule or proposition that is true\n\n\n\\(\\in\\)\n“in” or “element of”\nStates what something / an element is a member of\n\n\n|\nSuch that\nused in set theoretic definitions re: which values satisfy a particular (set of) condition(s)\n\n\n\\(\\notin\\)\nexcluding (element)\nStates that something is not a member of a set\n\n\n\\(\\equiv\\)\nequivalent\nSet theory equal\n\n\n\nFor example, \\(A = \\forall x \\in\\) the set of natural numbers that are divisible by 4 [FIX AND GIVE IS MORE EXAMPLES IN SLIDES]. This is telling us that A is a set of numbers that is comprised of natural numbers that are divisible by 4. We could list out the elements of this set. Note that curly brackets are always used for sets, never parentheses. E.g. {4, 8, 12, …} and not (4, 8, 12, …).",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#operators",
    "href": "math/01_notation.html#operators",
    "title": "Notation, Sets, and Functions",
    "section": "2.2 Operators",
    "text": "2.2 Operators\nWe can also symbols to denote operations between sets.\n\n\n\nNotation\nMeaning\nUse\n\n\n\n\n\\(\\subset\\)\nSubset\nLess than\n\n\n\\(\\subseteq\\)\nSubset\nLess than equal\n\n\n\\(\\varnothing\\)\nEmpty set\nZero\n\n\n\\(\\cap\\)\nIntersection\nAND\n\n\n\\(\\cup\\)\nUnion\nOR\n\n\n\\(\\setminus\\)\nDifference\nMinus (remove elements from sets)\n\n\n\nFor example, [EXAMPLE].",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#number-sets",
    "href": "math/01_notation.html#number-sets",
    "title": "Notation, Sets, and Functions",
    "section": "2.3 Number sets",
    "text": "2.3 Number sets\nCertain sets of numbers are so frequent they have their own notation.\n\n\n\n\n\n\n\n\nNotation\nMeaning\nUse\n\n\n\n\n\\(\\mathbb{N}\\)\nNatural numbers\n{(0), 1, 2, 3, 4, 5, …}\n\n\n\\(\\mathbb{Z}\\)\nIntegers (pos and neg)\n{…, -3, -2, -1, 0, 1, 2, 3, …}\n\n\n\\(\\mathbb{Q}\\)\nRational numbers (quotient)\n(all fractions–produced by numbers divided by an integer)\n\n\n\\(\\mathbb{R}\\)\nReal numbers (pos, neg, fractions)\n(any point on a number line)\n\n\n\\(\\mathbb{I}\\)\nImaginary number\ni = \\(\\sqrt(-1)\\)\n\n\n\\(\\mathbb{C}\\)\nComplex numbers\n(a + bi)",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#greek-letters",
    "href": "math/01_notation.html#greek-letters",
    "title": "Notation, Sets, and Functions",
    "section": "2.4 Greek letters",
    "text": "2.4 Greek letters\nGreek letters are often used to represent parameters or abstract quantities of interest. Below you can find the letter with its corresponding syntax for math mode in markdown languages (e.g. LaTeX, Typst).1\n\n\n\n\n\n\n\n\\(\\alpha\\) \\(A\\) \\alpha A\n\\(\\nu\\) \\(N\\) \\nu N\n\n\n\\(\\beta\\) \\(B\\) \\beta B\n\\(\\xi\\) \\(\\Xi\\) \\xi \\Xi\n\n\n\\(\\gamma\\) \\(\\Gamma\\) \\gamma \\Gamma\n\\(o\\) \\(O\\) o O (omicron)\n\n\n\\(\\delta\\) \\(\\Delta\\) \\delta \\Delta\n\\(\\pi\\) \\(\\Pi\\) \\pi \\Pi\n\n\n\\(\\epsilon\\) \\(\\varepsilon\\) \\epsilon \\varepsilon\n\\(\\rho\\) \\(\\varrho\\) P \\rho \\varrho P\n\n\n\\(\\zeta\\) \\(Z\\) \\zeta Z\n\\(\\sigma\\) \\(\\Sigma\\) \\sigma \\Sigma\n\n\n\\(\\eta\\) \\(H\\) \\eta H\n\\(\\tau\\) \\(T\\) \\tau T\n\n\n\\(\\theta\\) \\(\\vartheta\\) \\(\\Theta\\) \\theta \\vartheta \\Theta\n\\(\\upsilon\\) \\(\\Upsilon\\) \\upsilon \\Upsilon\n\n\n\\(\\iota\\) \\(I\\) \\iota I\n\\(\\phi\\) \\(\\varphi\\) \\(\\Phi\\) \\phi \\varphi \\Phi\n\n\n\\(\\kappa\\) \\(K\\) \\kappa K\n\\(\\chi\\) \\(X\\) \\chi X\n\n\n\\(\\lambda\\) \\(\\Lambda\\) \\lambda \\Lambda\n\\(\\psi\\) \\(\\Psi\\) \\psi \\Psi\n\n\n\\(\\mu\\) \\(M\\) \\mu M\n\\(\\omega\\) \\(\\Omega\\) \\omega \\Omega\n\n\n\nSomme commonly used Greek letters include:\n\n\\(\\delta\\) “delta” (used for integrals and discount factors in game theory)\n\\(\\Delta\\) “delta” (used for difference/change)\n\\(\\beta\\) “beta” (used for coefficients in regression)\n\\(\\mu\\) “mu” (used for means)\n\\(\\sigma\\) “sigma” (used for standard deviation)\n\\(\\lambda\\) “lambda” (used for eigenvalues in linear algebra)\n\\(\\epsilon\\) “epsilon” (used for the error term in regressions)\n\\(\\tau\\) “tau” (used for treatment effects in experiments)\n\nDifferent Greek letters are also used to denote in machine learning and Bayesian statistics.",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#footnotes",
    "href": "math/01_notation.html#footnotes",
    "title": "Notation, Sets, and Functions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://www.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols for details.↩︎",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#greek-vs.-latin-letters",
    "href": "math/01_notation.html#greek-vs.-latin-letters",
    "title": "Notation, Sets, and Functions",
    "section": "2.5 Greek vs. Latin letters",
    "text": "2.5 Greek vs. Latin letters\nIn papers using statistical methods, you may encounter a combination of Greek and English/Latin letters. Usage may vary depending on the application, but generally:\n\nGreek letters denote the unobserved truth that we want to learn about. For example, \\(\\mu\\) is the average adult height in the United States\nGreek letters with markings are our estimate of the truth based on our data. To calculate the average adult height, we use the mean \\(\\hat{\\mu}\\) (which we read as “mu hat”)\nLatin letters denote actual data in our sample, usually variables. For example, \\(X\\) is a collection of adult heights in a survey we conducted\nLatin letters with markings denote calculations in our data. For example, \\(\\bar{X}\\) (“X bar”) is the sample mean adult height\n\nThis means we use \\(X\\) in our data to calculate \\(\\bar{X}\\), which is our estimate \\(\\hat{\\mu}\\) of the unknown quantity \\(\\mu\\). A good statistical procedure yields a \\(\\hat{\\mu}\\) that approximates \\(\\mu\\), although this is generally hard to assess since \\(\\mu\\) is unobserved. If we knew the unknown quantity of interest, then no statistical analysis would be necessary.",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#proof-terms",
    "href": "math/01_notation.html#proof-terms",
    "title": "Notation, Sets, and Functions",
    "section": "3.1 Proof terms",
    "text": "3.1 Proof terms\nIn math, probability, statistics, and game theory, proofs often have different parts.\n\nAssumptions are statements taken to be true\nPropositions are statements thought to be true given the assumptions\nTheorems is a proven proposition\nLemmas are intermediary theorems that are not important on their own, but necessary to arrive at more important theorems or conclusions\nCorollaries are propositions that follow directly from the proof of another proposition and do not require further proof",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#necessary-and-sufficient",
    "href": "math/01_notation.html#necessary-and-sufficient",
    "title": "Notation, Sets, and Functions",
    "section": "3.2 Necessary and sufficient",
    "text": "3.2 Necessary and sufficient\nSometimes we want to understand the conditions that determine certain outcomes. To do this, the language of necessary and sufficient conditions is useful. Consider outcome Y and conditions A and B.\nA condition is sufficient if it occurs also when the outcome occurs. So, if A occurs when Y also occurs, they are sufficient for D to occur. D can happen without A, but we do not see A without D.\nA condition is necessary if we never see the outcome without it. So, if we observe Y, B must have also occurred. B can happen without Y, but never Y without B.\nSometimes, conditions operate in more complicated ways. We can have an Insufficient but Necessary part of an Unnecessary but Sufficient set of conditions an outcome to occur (INUS). For example, having unprotected sexual intercourse is insufficient for HIV transmission, but it can be necessary part of one of the many ways in which HIV is transmitted. Informally, it helps to think about INUS conditions as component causes.\nAlso, we can have Sufficient but Unnecessary condition that is part of a condition set that is Insufficient but Necessary for the outcome. For example, fraudulent elections are a sufficient but unnecessary condition to erode democracy. In turn, per the democratic peace theory, the absence of democracy is necessary but not sufficient to cause war. It helps to think of SUIN conditions as precipitating causes.",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#logical-operators",
    "href": "math/01_notation.html#logical-operators",
    "title": "Notation, Sets, and Functions",
    "section": "3.3 Logical operators",
    "text": "3.3 Logical operators\nLike regular math operators, logical operators denote operations on sets. Some of these are useful for data analysis work. For example, when subsetting data. Most of these operators exist in R and other statistical computing software, although sometimes with modified syntax.\n\n\n\n\n\n\n\n\nNotation\nMeaning\nUse\n\n\n\n\n\\(\\wedge\\)\nAnd\nIntersection.Discussing elements in both sets\n\n\n\\(\\vee\\)\nOr\nUnion. Discussing elements that are in multiple sets\n\n\n\\(\\sim\\)\nNot\nNegation\n\n\n!\nNot\nNegation (used in R most often)\n\n\n&lt;\nLess than\nInequality(good for specifying conditions when filtering)\n\n\n&lt;=\nLess than equal to\nInequality (good for specifying conditions when filtering; include the value)\n\n\n&gt;\nGreater than\nInequality (good for specifying conditions when filtering)\n\n\n&gt;=\nGreater than equal to\nInequality (good for specifying conditions when filtering; include the value)\n\n\n!=\nNot equal to\nExclude values when filtering (anything other than the exact value)\n\n\n==\nExactly equal\nHelpful in R for when a value is exactly satisfied\n\n\n%in%\nIn\nUseful when searching for terms",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/01_notation.html#proofs",
    "href": "math/01_notation.html#proofs",
    "title": "Notation, Sets, and Functions",
    "section": "3.4 Proofs",
    "text": "3.4 Proofs\nWe won’t do proofs in Math Camp, but we’ll reference them implicitly throughout the course and in they may come back in your fall coursework.\n\n3.4.1 Direct proofs\nDirect proofs work through proof and typically use one of the following methods: + General (deductive) proof: typically done using definitions, etc. Showing how the outcome logically follows building on rules and assumptions. + Proof by exhaustion: Break up the outcome into sub cases and show for each case (done often in game theory for possible values) + Proof by construction: These proofs demonstrate existence (is there a square that is the sum of two squares?). + Proof by induction: Start small and show it is true for any number (e.g. start with a small n, n=1, then expand to n+1)\n\n\n3.4.2 Indirect proofs\nThese show that the outcome must be true because there is no possible alternative.These are typically demonstrated using the following methods:\n\nProof by counterexample: using a counterexample (x implies y, yet we observe y without x…x cannot imply y (aka x not necessary for y)).\nProof by contradiction: assume that the statement is false and try to prove it wrong, eventually demonstrating that a contradiction emerges. Thus, the statement cannot be false.",
    "crumbs": [
      "Math",
      "1. Notations, sets, functions"
    ]
  },
  {
    "objectID": "math/02_matrices.html#introduction",
    "href": "math/02_matrices.html#introduction",
    "title": "Matrices",
    "section": "",
    "text": "A single number (for example, 12) is referred to as a scalar.\n\\[\na = 12\n\\]\n\n\n\nWe can put several scalars together to make a vector. Vectors are usually denoted with an arrow on top, although social scientist tend to forgo this convention. Here is an example:\n\\[\n\\overrightarrow b =\n\\begin{bmatrix}\n  12 \\\\\n  14 \\\\\n  15\n\\end{bmatrix}\n\\]\nSince this is a column of numbers, we refer to it as a column vector.\nOf course, we can also have row vectors:\n\\[\n\\overrightarrow c = \\begin{bmatrix}\n  12 & 14 & 15\n\\end{bmatrix}\n\\]\nNote that we use brackets \\([ ... ]\\) to demarcate vectors and matrices.\nIn R, we can construct vectors with the the c() function to combine elements (the c stands for concatenate):\n\nc(5, 25, -2, 1)\n\n[1]  5 25 -2  1\n\n\nWe can also create vectors that follow a pattern with the : operator or the seq() function:\n\n10:20\n\n [1] 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nseq(from = 3, to = 27, by = 3)\n\n[1]  3  6  9 12 15 18 21 24 27",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#operators",
    "href": "math/02_matrices.html#operators",
    "title": "Matrices",
    "section": "",
    "text": "The summation operator \\(\\sum\\) (i.e., the uppercase Sigma letter) lets us perform an operation on a sequence of numbers, which is often but not always a vector.\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & -1\n\\end{bmatrix}\\]\nWe can then calculate the sum of the first three elements of the vector, which is expressed as follows: \\[\\sum_{i=1}^3 d_i\\]\nThen we do the following math: \\[12+7+(-2)=17\\]\nIt is also common to use \\(n\\) in the superscript to indicate that we want to sum up to the very last element:\n\\[\n\\sum_{i=1}^n d_i = 12 + 7 + (-2) + 3 + (-1) = 19\n\\]\nWe can perform these operations using the sum() function in R:\n\nd = c(12, 7, -2, 3, -1)\n\n\nsum(d)\n\n[1] 19\n\n\n\nsum(d[1:3])\n\n[1] 17\n\n\n\nsum(d)\n\n[1] 19\n\n\n\n\n\nThe product operator \\(\\prod\\) (uppercase Pi) can also perform operations over a sequence of elements in a vector. Recall our previous vector:\n\\[\\overrightarrow d = \\begin{bmatrix}\n12 & 7 & -2 & 3 & 1\n\\end{bmatrix}\\]\nWe might want to calculate the product of all its elements, which is expressed as follows: \\[\\prod_{i=1}^n d_i = 12 \\cdot 7 \\cdot (-2) \\cdot 3 \\cdot (-1) = 504\\]\nIn R, we can compute products using the prod() function:\n\nprod(d)\n\n[1] 504",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#matrices-1",
    "href": "math/02_matrices.html#matrices-1",
    "title": "Matrices",
    "section": "",
    "text": "We can append vectors together to form a matrix:\n\\[A = \\begin{bmatrix}\n12 & 14 & 15 \\\\\n115 & 22 & 127 \\\\\n193 & 29 & 219\n\\end{bmatrix}\\]\nThe number of rows and columns of a matrix constitute the dimensions of the matrix. The first number is the number of rows (“r”) and the second number is the number of columns (“c”) in the matrix. The order of dimensions never changes.\nMatrix \\(A\\) above, for example, is a \\(3 \\times 3\\) matrix. Sometimes we’d refer to it as \\(A_{3 \\times 3}\\). We commonly use capital letters to represent matrices. Sometimes, vectors and matrices are further denoted with bold font.\n\n\nThere are different ways to create matrices in R. One of the simplest is via rbind() or cbind(), which paste vectors together (either by rows or by columns):\n\n# Create some vectors\nvector1 = 1:4\nvector2 = 5:8\nvector3 = 9:12\nvector4 = 13:16\n\n\n# Using rbind(), each vector will be a row \nrbind_mat = rbind(vector1, vector2, vector3, vector4)\nrbind_mat\n\n        [,1] [,2] [,3] [,4]\nvector1    1    2    3    4\nvector2    5    6    7    8\nvector3    9   10   11   12\nvector4   13   14   15   16\n\n\n\n# Using cbind(), each vector will be a column\ncbind_mat = cbind(vector1, vector2, vector3, vector4)\ncbind_mat\n\n     vector1 vector2 vector3 vector4\n[1,]       1       5       9      13\n[2,]       2       6      10      14\n[3,]       3       7      11      15\n[4,]       4       8      12      16\n\n\nAn alternative is to use to properly named matrix() function. The basic syntax is matrix(data, nrow, ncol, byrow):\n\ndata is the input vector which becomes the data elements of the matrix.\nnrow is the number of rows to be created.\nncol is the number of columns to be created.\nbyrow is a logical clue. If TRUE then the input vector elements are arranged by row. By default (FALSE), elements are arranged by column.\n\nLet’s see some examples:\n\n# Elements are arranged sequentially by row.\nM = matrix(c(1:12), nrow = 4, byrow = T)\nM\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n\n\n# Elements are arranged sequentially by column (byrow = F by default).\nN = matrix(c(1:12), nrow = 4)\nN\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\n\n\n\n\n[CONTINUE HERE]\nHow do we refer to specific elements of the matrix? For example, matrix \\(A\\) is an \\(m\\times n\\) matrix where \\(m=n=3\\). This is sometimes called a square matrix.\nMore generally, matrix \\(B\\) is an \\(m\\times n\\) matrix where the elements look like this: \\[B=\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & \\ldots & b_{1n} \\\\\nb_{21} & b_{22} & b_{23} & \\ldots & b_{2n} \\\\\n\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\nb_{m1} & b_{m2} & b_{m3} & \\ldots & b_{mn}\n\\end{bmatrix}\\]\nThus \\(b_{23}\\) refers to the second unit down and third across. More generally, we refer to row indices as \\(i\\) and to column indices as \\(j\\).\nIn R, we can access a matrix’s elements using square brackets:\n\n# In matrix N, access the element at 1st row and 3rd column.\nN[1,3]\n\n[1] 9\n\n\n\n# In matrix N, access the element at 4th row and 2nd column.\nN[4,2]\n\n[1] 8\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen trying to identify a specific element, the first subscript is the element’s row and the second subscript is the element’s column (always in that order).\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn R, indexing is 1-based, meaning that the first element of a vector, matrix, or any other data structure is accessed with index 1. In other programming tools such as Python, indexing is 0-based, meaning that the first element of a list, array, or any other data structure is accessed with index 0.\n\n# Create a 2x2 matrix in R\nmatrix_A = matrix(1:4, nrow = 2, ncol = 2)\n\n# Access the element in the first row, first column\nelement = matrix_A[1, 1]  # This will return 1\n\n# Create a list in Python\nvector = [10, 20, 30, 40]\n\n# Access the first element\nfirst_element = vector[0]  # This will return 10\nimport numpy as np\n\n# Create a 2x2 matrix in Python with NumPy\nmatrix_A = np.array([[1, 2], [3, 4]])\n\n# Access the element in the first row, first column\nelement = matrix_A[0, 0]  # This will return 1",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#matrix-operations",
    "href": "math/02_matrices.html#matrix-operations",
    "title": "Matrices",
    "section": "",
    "text": "Addition and subtraction are straightforward operations.\nMatrices must have exactly the same dimensions for both of these operations.\nWe add or subtract each element with the corresponding element from the other matrix.\nThis is expressed as follows:\n\n\\[A \\pm B=C\\]\n\\[c_{ij}=a_{ij} \\pm b_{ij} \\text{ }\\forall i,j\\]\n\\[\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\pm\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13}\\\\\nb_{21} & b_{22} & b_{23}\\\\\nb_{31} & b_{32} & b_{33}\n\\end{bmatrix}\\] \\[=\\] \\[\\begin{bmatrix}\na_{11}\\pm b_{11} & a_{12}\\pm b_{12} & a_{13}\\pm b_{13}\\\\\na_{21}\\pm b_{21} & a_{22}\\pm b_{22} & a_{23}\\pm b_{23}\\\\\na_{31}\\pm b_{31} & a_{32}\\pm b_{32} & a_{33}\\pm b_{33}\n\\end{bmatrix}\\]\n\n\nWe start by creating two 2x3 matrices:\n\\[A= \\begin{bmatrix}\n3 & -1 & 2  \\\\\n9 & 4 & 6\n\\end{bmatrix}\\]\n\n# Create two 2x3 matrices.\nmatrix1 = matrix(c(3, 9, -1, 4, 2, 6), nrow = 2)\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\nAnd \\[B= \\begin{bmatrix}\n5 & 2 & 0  \\\\\n9 & 3 & 4\n\\end{bmatrix}\\]\n\nmatrix2 = matrix(c(5, 2, 0, 9, 3, 4), nrow = 2)\nmatrix2\n\n     [,1] [,2] [,3]\n[1,]    5    0    3\n[2,]    2    9    4\n\n\nWe can simply use the + and - operators for addition and substraction:\n\nmatrix1 + matrix2\n\n     [,1] [,2] [,3]\n[1,]    8   -1    5\n[2,]   11   13   10\n\n\n\nmatrix1 - matrix2\n\n     [,1] [,2] [,3]\n[1,]   -2   -1   -1\n[2,]    7   -5    2\n\n\n\n\n\n\n\n\nExercise\n\n\n\n(Use code for one of these and do the other one by hand!)\n1) Calculate \\(A + B\\)\n\\[A= \\begin{bmatrix}\n1 & 0 \\\\\n-2 & -1\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n5 & 1 \\\\\n2 & -1\n\\end{bmatrix}\\]\n\n2) Calculate \\(A - B\\)\n\\[A= \\begin{bmatrix}\n6 & -2 & 8 & 12 \\\\\n4 & 42 & 8 & -6\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n18 & 42 & 3 & 7 \\\\\n0 & -42 & 15 & 4\n\\end{bmatrix}\\]\n\n\n\n\n\n\nScalar multiplication is very intuitive. As we know, a scalar is a single number. We multiply each value in the matrix by the scalar to perform this operation.\nFormally, this is expressed as follows: \\[A =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\] \\[cA =\n\\begin{bmatrix}\nca_{11} & ca_{12} & ca_{13}\\\\\nca_{21} & ca_{22} & ca_{23}\\\\\nca_{31} & ca_{32} & ca_{33}\n\\end{bmatrix}\\]\nIn R, all we need to do is take an established matrix and multiply it by some scalar:\n\n# matrix1 from our previous example\nmatrix1\n\n     [,1] [,2] [,3]\n[1,]    3   -1    2\n[2,]    9    4    6\n\n\n\nmatrix1 * 3\n\n     [,1] [,2] [,3]\n[1,]    9   -3    6\n[2,]   27   12   18\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCalculate \\(2\\times A\\) and \\(-3 \\times B\\). Again, do one by hand and the other one using R.\n\\[A= \\begin{bmatrix}\n    1 & 4 & 8 \\\\\n    0 & -1 & 3\n    \\end{bmatrix}\\] \\[ B = \\begin{bmatrix}\n    -15 & 1 & 5 \\\\\n    2 & -42 & 0 \\\\\n    7 & 1 & 6\n    \\end{bmatrix}\\]\n\n\n\n\n\n\nMultiplying matrices is slightly trickier than multiplying scalars.\nTwo matrices must be conformable for them to be multiplied together. This means that the number of columns in the first matrix equals the number of rows in the second.\nWhen multiplying \\(A \\times B\\), if \\(A\\) is \\(m \\times n\\), \\(B\\) must have \\(n\\) rows.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe conformability requirement never changes. Before multiplying anything, check to make sure the matrices are indeed conformable.\n\n\n\nThe resulting matrix will have the same number of rows as the first matrix and the number of columns in the second. For example, if \\(A\\) is \\(i \\times k\\) and \\(B\\) is \\(k \\times j\\), then \\(A \\times B\\) will be \\(i \\times j\\).\n\n\nWhich of the following can we multiply? What will be the dimensions of the resulting matrix? \\[\\begin{aligned}\nB_{4 \\times 1}=\n\\begin{bmatrix}\n2 \\\\\n3\\\\\n4\\\\\n1\n\\end{bmatrix}\nM_{3 \\times 3} =\n\\begin{bmatrix}\n1 & 0 & 2\\\\\n1 & 2 & 4\\\\\n2 & 3 & 2\n\\end{bmatrix}\nL_{2 \\times 3} =\n\\begin{bmatrix}\n6 & 5 & -1\\\\\n1 & 4 & 3\n\\end{bmatrix}\n\\end{aligned}\\]\nThe only valid multiplication based on the provided matrices is \\(L \\times M\\), which results in a \\(2 \\times 3\\) matrix.\nWhy can’t we multiply in the opposite order?\nThe non-commutative property of matrix multiplication is a fundamental aspect in matrix algebra. The multiplication of matrices is sensitive to the order in which the matrices are multiplied due to the requirements of dimensional compatibility, the resulting dimensions, and the computation process itself.\n\n\n\n\n\n\nWarning\n\n\n\nWhen multiplying matrices, order matters. Even if multiplication is possible in both directions, in general \\(AB \\neq BA\\).\n\n\n\n\n\nMultiply each row by each column, summing up each pair of multiplied terms.\n\n\n\n\n\n\n\nTip\n\n\n\nThis is sometimes to referred to as the “dot product,” where we multiply matching members, then sum up.\n\n\n\nThe element in position \\(ij\\) is the sum of the products of elements in the \\(i\\)th row of the first matrix (\\(A\\)) and the corresponding elements in the \\(j\\)th column of the second matrix (\\(B\\)). \\[c_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}\\]\n\n\n\n\nSuppose a company manufactures two kinds of furniture: chairs and sofas.\n\nA chair costs $100 for wood, $270 for cloth, and $130 for feathers.\nEach sofa costs $150 for wood, $420 for cloth, and $195 for feathers.\n\n\n\n\n\nChair\nSofa\n\n\n\n\nWood\n100\n150\n\n\nCloth\n270\n420\n\n\nFeathers\n130\n195\n\n\n\nThe same information about unit cost (\\(C\\)) can be presented as a matrix.\n\\[C = \\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\\]\nNote that each of the three rows of this 3 x 2 matrix represents a material (wood, cloth, or feathers), and each of the two columns represents a product (chair or coach). The elements are the unit cost (in USD).\n\nNow, suppose that the company will produce 45 chairs and 30 sofas this month. This production quantity can be represented in the following table, and also as a 2 x 1 matrix (\\(Q\\)):\n\n\n\nProduct\nQuantity\n\n\n\n\nChair\n45\n\n\nSofa\n30\n\n\n\n\\[Q = \\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix}\\]\nWhat will be the company’s total cost? The “total expenditure” is equal to the “unit cost” times the “production quantity” (the number of units).\nThe total expenditure (\\(E\\)) for each material this month is calculated by multiplying these two matrices.\n\\[\\begin{aligned} E = CQ =\n\\begin{bmatrix}\n100 & 150\\\\\n270 & 420\\\\\n130 & 195\n\\end{bmatrix}\n\\begin{bmatrix}\n45 \\\\\n30\n\\end{bmatrix} =\n\\begin{bmatrix}\n(100)(45) + (150)(30) \\\\\n(270)(45) + (420)(30) \\\\\n(130)(45) + (195)(30)\n\\end{bmatrix} =\n\\begin{bmatrix}\n9,000 \\\\\n24,750 \\\\\n11,700\n\\end{bmatrix}\n\\end{aligned}\\]\nMultiplying the 3x2 Cost matrix (\\(C\\)) times the 2x1 Quantity matrix (\\(Q\\)) yields the 3x1 Expenditure matrix (\\(E\\)).\nAs a result of this matrix multiplication, we determine that this month the company will incur expenditures of:\n\n$9,000 for wood\n$24,750 for cloth\n$11,700 for feathers.\n\n\n\n\nBefore attempting matrix multiplication, we must make sure the matrices are conformable (as we do for our manual calculations).\nThen we can multiply our matrices together using the %*% operator.\n\nC = matrix(c(100, 270, 130, 150, 420, 195), nrow = 3)\nC\n\n     [,1] [,2]\n[1,]  100  150\n[2,]  270  420\n[3,]  130  195\n\n\n\nQ = matrix(c(45, 30), nrow = 2)\nQ\n\n     [,1]\n[1,]   45\n[2,]   30\n\n\n\nC %*% Q\n\n      [,1]\n[1,]  9000\n[2,] 24750\n[3,] 11700\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you have a missing value or NA in one of the matrices you are trying to multiply (something we will discuss in further detail in the next module), you will have NAs in your resulting matrix.\n\n\n\n\n\n\n\n\nAddition and subtraction:\n\nAssociative: \\((A \\pm B) \\pm C = A \\pm (B \\pm C)\\)\nCommunicative: \\(A \\pm B = B \\pm A\\)\n\nMultiplication:\n\n\\(AB \\neq BA\\)\n\\(A(BC) = (AB)C\\)\n\\(A(B+C) = AB + AC\\)\n\\((A+B)C = AC + BC\\)",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#special-matrices",
    "href": "math/02_matrices.html#special-matrices",
    "title": "Matrices",
    "section": "",
    "text": "Square matrix\n\\[\nA = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{bmatrix}\n\\]\n\nIn a square matrix, the number of rows equals the number of columns (\\(m=n\\)):\nThe diagonal of a matrix is a set of numbers consisting of the elements on the line from the upper-left-hand to the lower-right-hand corner of the matrix, as in $ d(A)=[1,5,9] $. Diagonals are particularly useful in square matrices.\nThe trace of a matrix, denoted as \\(tr(A)\\), is the sum of the diagonal elements of the matrix. \\(tr(A) = 1+5+9 = 15\\)\n\nDiagonal matrix:\n\nIn a diagonal matrix, all of the elements of the matrix that are not on the diagonal are equal to zero. \\[\nD = \\begin{bmatrix}\n4 & 0 & 0 \\\\\n0 & 5 & 0 \\\\\n0 & 0 & 6\n\\end{bmatrix}\n\\]\n\nScalar matrix:\n\nA scalar matrix is a diagonal matrix where the diagonal elements are all equal to each other. In other words, we’re really only concerned with one scalar (or element) held in the diagonal.\n\n\\[\nS = \\begin{bmatrix}\n7 & 0 & 0 \\\\\n0 & 7 & 0 \\\\\n0 & 0 & 7\n\\end{bmatrix}\n\\]\nIdentity matrix:\n\\[\nI = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\n\nThe identity matrix is a scalar matrix with all of the diagonal elements equal to one.\nRemember that, as with all diagonal matrices, the off-diagonal elements are equal to zero.\nThe capital letter \\(I\\) is reserved for the identity matrix. For convenience, a 3x3 identity matrix can be denoted as \\(I_3\\).",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#transpose",
    "href": "math/02_matrices.html#transpose",
    "title": "Matrices",
    "section": "",
    "text": "The transpose is the original matrix with the rows and the columns interchanged.\nThe notation is either \\(J'\\) (“J prime”) or \\(J^T\\) (“J transpose”).\n\\[J =\n\\begin{bmatrix}\n4 & 5\\\\\n3 & 0\\\\\n7 & -2\n\\end{bmatrix}\\]\n\\[J' = J^T =\n\\begin{bmatrix}\n4 & 3 & 7 \\\\\n5 & 0 & -2\n\\end{bmatrix}\\]\nIn R, we use t() to get the transpose.\n\nJ = matrix(c(4, 3, 7, 5, 0, -2), ncol = 2)\nJ\n\n     [,1] [,2]\n[1,]    4    5\n[2,]    3    0\n[3,]    7   -2\n\n\n\nt(J)\n\n     [,1] [,2] [,3]\n[1,]    4    3    7\n[2,]    5    0   -2",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#inverse",
    "href": "math/02_matrices.html#inverse",
    "title": "Matrices",
    "section": "",
    "text": "Just like a number has a reciprocal, a matrix has an inverse.\nWhen we multiply a matrix by its inverse we get the identity matrix (which is like “1” for matrices).\n\n\\[A × A^{-1} = I\\]\n\nThe inverse of A is \\(A^{-1}\\) only when:\n\n\\[AA^{-1} = A^{-1}A = I\\]\n\nSometimes there is no inverse at all.\n\n\n\n\n\n\n\nNote\n\n\n\nFor now, don’t worry about calculating the inverse of a matrix manually. This is the type of task we use R for.\n\n\n\nIn R, we use the solve() function to calculate the inverse of a matrix:\n\n\nA = matrix(c(3, 2, 5, 2, 3, 2, 5, 2, 4), ncol = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    3    2    5\n[2,]    2    3    2\n[3,]    5    2    4\n\n\n\nsolve(A)\n\n            [,1]        [,2]       [,3]\n[1,] -0.29629630 -0.07407407  0.4074074\n[2,] -0.07407407  0.48148148 -0.1481481\n[3,]  0.40740741 -0.14814815 -0.1851852",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#linear-systems-and-matrices",
    "href": "math/02_matrices.html#linear-systems-and-matrices",
    "title": "Matrices",
    "section": "",
    "text": "A system of equations can be represented by an augmented matrix.\nSystem of equations: \\[{\\color{red}{3}}x + {\\color{green}{6}}y = {\\color{blue}{12}}\\] \\[{\\color{red}{5}}x + {\\color{green}{10}}y = {\\color{blue}{25}}\\]\nIn an augmented matrix, each row represents one equation in the system and each column represents a variable or the constant terms. \\[\\begin{bmatrix}\n{\\color{red}{3}} & {\\color{green}{6}} & {\\color{blue}{12}}\\\\\n{\\color{red}{5}} & {\\color{green}{10}} & {\\color{blue}{25}}\n\\end{bmatrix}\\]",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  },
  {
    "objectID": "math/02_matrices.html#ols-and-matrices",
    "href": "math/02_matrices.html#ols-and-matrices",
    "title": "Matrices",
    "section": "",
    "text": "We can use the logic above to calculate estimates for our ordinary least squares (OLS) models.\nOLS is a linear regression technique used to find the best-fitting line for a set of data points (observations) by minimizing the residuals (the differences between the observed and predicted values).\nWe minimize the sum of the squared errors.\n\n\n\n\nSuppose, for example, we have a sample consisting of \\(n\\) observations.\nThe dependent variable is denoted as an \\(n \\times1\\) column vector.\n\n\\[Y = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\\]\n\n\n\n\nSuppose there are \\(k\\) independent variables and a constant term, meaning \\(k+1\\) columns and \\(n\\) rows.\nWe can represent these variables as an \\(n \\times (k+1)\\) matrix, expressed as follows:\n\n\\[X= \\begin{bmatrix}\n1 & x_{11} & \\dots & x_{1k} \\\\\n1 & x_{21} & \\dots & x_{2k} \\\\\n\\vdots & \\vdots & \\dots & \\vdots \\\\\n1 & x_{n1} & \\dots & x_{nk}\n\\end{bmatrix}\\]\n\n\\(x_{ij}\\) is the \\(i\\)-th observation of the \\(j\\)-th independent variable.\n\n\n\n\n\nLet’s say we have 173 observations (n = 173) and 2 IVs (k = 3).\nThis can be expressed as the following linear equation: \\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon\\]\nIn matrix form, we have: \\[\\begin{aligned} \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} = \\begin{bmatrix}\n1 & x_{11} & x_{21} \\\\\n1 & x_{21} & x_{22} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_{1173} & x_{2173}\n\\end{bmatrix} \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{bmatrix} + \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_{173}\n\\end{bmatrix}\\end{aligned} \\]\nAll 173 equations can be represented by: \\[y=X\\beta+\\epsilon\\]\n\n\n\n\n\nWithout getting too much into the mechanics, we can calculate our coefficient estimates with matrix algebra using the following equation:\n\n\\[\\hat{\\beta} = (X'X)^{-1}X'Y\\]\n\nRead aloud, we say “X prime X inverse, X prime Y”.\nThe little hat on our beta (\\(\\hat{\\beta}\\)) signifies that these are estimates.\nRemember, the OLS method is to choose \\(\\hat{\\beta}\\) such that the sum of squared residuals (“SSR”) is minimized.\n\n\n\n\nWe will load the mtcars data set (our favorite) for this example, which contains data about many different car models.\n\n\ncars_df = mtcars\n\n\nNow, we want to estimate the association between hp (horsepower) and wt (weight), our independent variables, and mpg (miles per gallon), our dependent variable.\nFirst, we transform our dependent variable into a matrix, using the as.matrix function and specifying the column of the mtcars data set to create a column vector of our observed values for the DV.\n\n\nY = as.matrix(cars_df$mpg)\nY\n\n      [,1]\n [1,] 21.0\n [2,] 21.0\n [3,] 22.8\n [4,] 21.4\n [5,] 18.7\n [6,] 18.1\n [7,] 14.3\n [8,] 24.4\n [9,] 22.8\n[10,] 19.2\n[11,] 17.8\n[12,] 16.4\n[13,] 17.3\n[14,] 15.2\n[15,] 10.4\n[16,] 10.4\n[17,] 14.7\n[18,] 32.4\n[19,] 30.4\n[20,] 33.9\n[21,] 21.5\n[22,] 15.5\n[23,] 15.2\n[24,] 13.3\n[25,] 19.2\n[26,] 27.3\n[27,] 26.0\n[28,] 30.4\n[29,] 15.8\n[30,] 19.7\n[31,] 15.0\n[32,] 21.4\n\n\n\nNext, we do the same thing for our independent variables of interest, and our constant.\n\n\n# create two separate matrices for IVs\nX1 = as.matrix(cars_df$hp)\nX2 = as.matrix(cars_df$wt)\n\n# create constant column\n\n# bind them altogether into one matrix\nconstant =  rep(1, nrow(cars_df))\nX = cbind(constant, X1, X2)\nX\n\n      constant          \n [1,]        1 110 2.620\n [2,]        1 110 2.875\n [3,]        1  93 2.320\n [4,]        1 110 3.215\n [5,]        1 175 3.440\n [6,]        1 105 3.460\n [7,]        1 245 3.570\n [8,]        1  62 3.190\n [9,]        1  95 3.150\n[10,]        1 123 3.440\n[11,]        1 123 3.440\n[12,]        1 180 4.070\n[13,]        1 180 3.730\n[14,]        1 180 3.780\n[15,]        1 205 5.250\n[16,]        1 215 5.424\n[17,]        1 230 5.345\n[18,]        1  66 2.200\n[19,]        1  52 1.615\n[20,]        1  65 1.835\n[21,]        1  97 2.465\n[22,]        1 150 3.520\n[23,]        1 150 3.435\n[24,]        1 245 3.840\n[25,]        1 175 3.845\n[26,]        1  66 1.935\n[27,]        1  91 2.140\n[28,]        1 113 1.513\n[29,]        1 264 3.170\n[30,]        1 175 2.770\n[31,]        1 335 3.570\n[32,]        1 109 2.780\n\n\n\nNext, we calculate \\(X'X\\), \\(X'Y\\), and \\((X'X)^{-1}\\).\n\n\nDon’t forget to use %*% for matrix multiplication!\n\n\n# X prime X\nXpX = t(X) %*% X\n\n# X prime X inverse\nXpXinv = solve(XpX)\n\n# X prime Y\nXpY = t(X) %*% Y\n\n# beta coefficient estimates\nbhat = XpXinv %*% XpY\nbhat\n\n                [,1]\nconstant 37.22727012\n         -0.03177295\n         -3.87783074",
    "crumbs": [
      "Math",
      "2. Matrices"
    ]
  }
]